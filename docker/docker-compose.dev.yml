version: '3.8'

services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama-dev
    ports:
      - "11434:11434"
    volumes:
      - ./models:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped

  coding-agent:
    build:
      context: ..
      dockerfile: docker/Dockerfile.dev
    container_name: coding-agent-dev
    ports:
      - "8000:8000"
    volumes:
      - ../src:/app/src
      - ../workspace:/workspace
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - MODEL_NAME=qwen2.5-coder:7b
      - API_PORT=8000
      - LOG_LEVEL=DEBUG
      - WORKSPACE_PATH=/workspace
      - MAX_FILE_SIZE=104857600
    depends_on:
      - ollama
    restart: unless-stopped

networks:
  default:
    name: coding-agent-dev-network
